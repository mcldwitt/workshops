{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcldwitt/workshops/blob/main/Deep_learning_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='darkorange'> Welcome to the reinforcement learning workshop!\n",
        "\n",
        "To run a cel click on the play button next to it\n",
        "\n",
        "<font color='red'>do not forget to run the first cell!</font> This will import all the necesary functions, modules and data.  \n",
        "This might take a while"
      ],
      "metadata": {
        "id": "PhmUCCCkOM7V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQYNk5GUmY2c"
      },
      "outputs": [],
      "source": [
        "# This might take a while\n",
        "!pip install lime==0.2.0.1\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import os,sys\n",
        "try:\n",
        "    import lime\n",
        "except:\n",
        "    sys.path.append(os.path.join('..', '..')) # add the current directory\n",
        "    import lime\n",
        "from lime import lime_image\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "from skimage.io import imread, imsave, imshow\n",
        "from skimage import data, color, io, filters, morphology,transform, exposure, feature, util\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "from skimage.color import rgb2gray\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "from skimage.segmentation import mark_boundaries\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/mcldwitt/workshops/archive/refs/heads/main.zip\" \n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile('main.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('.') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()\n",
        "\n",
        "def histplot(history, name):\n",
        "    fig, axs = plt.subplots(1,2, figsize=(12,6))\n",
        "    print(fig)\n",
        "\n",
        "    axs[0].plot(history.history['loss'],'red',linewidth=3.0, label=\"loss\")\n",
        "    axs[0].plot(history.history['val_loss'],'blue',linewidth=3.0, label=\"val_loss\")\n",
        "    axs[0].legend()\n",
        "    axs[0].set_xlabel('epochs')\n",
        "    axs[0].set_ylabel('Training error')\n",
        "    axs[0].set_ylim((0,1.5))\n",
        "    axs[0].grid()\n",
        "    axs[0].set_title(name)\n",
        "\n",
        "    axs[1].plot(history.history['accuracy'],'red',linewidth=3.0, label=\"accuracy\")\n",
        "    axs[1].plot(history.history['val_accuracy'],'blue',linewidth=3.0, label=\"val_accuracy\")\n",
        "    axs[1].legend()\n",
        "    axs[1].set_xlabel('epochs')\n",
        "    axs[1].set_ylabel('Accuracy')\n",
        "    axs[1].grid()\n",
        "    fig.savefig(name+'.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> Let's start with importing the data.</font>  \n",
        "We will be working with images containing either spiders or elephants."
      ],
      "metadata": {
        "id": "i0p-Lte1Os2B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwRoIa-mLicr"
      },
      "outputs": [],
      "source": [
        "path = ['./workshops-main/elephant', './workshops-main/spiders']\n",
        "valid_images = [\".jpg\",\".gif\",\".png\"]\n",
        "images = []\n",
        "y = []\n",
        "grayscale = False\n",
        "\n",
        "\n",
        "for p in path:\n",
        "  for f in os.listdir(p)[:]:\n",
        "      ext = os.path.splitext(f)[1]\n",
        "      if ext.lower() not in valid_images:\n",
        "        continue\n",
        "\n",
        "\n",
        "      im = imread(os.path.join(p,f)) \n",
        "      im = transform.resize(im,(200,200,3),mode='constant',anti_aliasing=True)\n",
        "      images.append(np.array(im))\n",
        "      x = p.split(\"/\")\n",
        "      y.append(x[2])\n",
        "\n",
        "images = np.array(images)\n",
        "y = np.array(y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> Now we are going to visualise some of the samples.</font>  \n"
      ],
      "metadata": {
        "id": "_u8yGB2zPRFx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm7NIQWOMuGi"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "samples = random.sample(range(1, len(y)), 10)\n",
        "print(samples)\n",
        "\n",
        "fig, axs = plt.subplots(1,10, figsize=(30,10))\n",
        "axs[0].set_title(\"dataset\")\n",
        "for img, a in zip(samples, axs):\n",
        "    a.imshow(images[img])\n",
        "    a.set_axis_off()\n",
        "    a.title.set_text(y[img])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> It's important we have approximatly the same amount of images with spiders and elephants in our dataset. Let's visualise this.</font>  "
      ],
      "metadata": {
        "id": "QVt6XhpFPi_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert code here"
      ],
      "metadata": {
        "id": "nB0s-WZAQQgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> "
      ],
      "metadata": {
        "id": "epcFnAcRQzNZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXUOhyBthPaV"
      },
      "outputs": [],
      "source": [
        "ind_list = [i for i in range(len(y))]\n",
        "shuffle(ind_list)\n",
        "\n",
        "X = images[ind_list]\n",
        "y = y[ind_list]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> Let's convert the target into numbers, and check wether we need to standardise our data </font>"
      ],
      "metadata": {
        "id": "p-_xl0TIRJz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "helxQd5gaQpM"
      },
      "outputs": [],
      "source": [
        "# checking standardisation\n",
        "print(\"Range of input values : \", (X.min(), X.max()))\n",
        "\n",
        "# convert the target\n",
        "print(y)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> Splitting the data into train and test_set"
      ],
      "metadata": {
        "id": "pQQL-gzBSGlu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8Db7HrTdF5-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> Creating the AI model"
      ],
      "metadata": {
        "id": "3uIf9yIlSHeE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btKDUk9camwL"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train[0].shape\n",
        "\n",
        "# Model\n",
        "model = Sequential()\n",
        "\n",
        "# You can add additional convolutional layers and maxpooling layers\n",
        "\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu',input_shape=input_shape)) \n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu')) \n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Flatten()) \n",
        "model.add(Dense(5, activation='relu')) # you can change the number of neurons or add an aditional dense layer\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "    \n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> Training the AI model"
      ],
      "metadata": {
        "id": "TpdgrZuiSIaq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXIbR1lRc1GZ"
      },
      "outputs": [],
      "source": [
        "batch_size = 64 # you can change the number, but it should be a multiple of 8\n",
        "epochs     = 50 # you can chance te number ranging from 1 to 300\n",
        "\n",
        "mc = ModelCheckpoint('best_model1.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 10)\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, validation_split = 0.1, epochs=epochs, verbose=1,\n",
        "                   callbacks=[es, mc])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> How did the model perform? </font>\n",
        "We want the accuracy as close to 1 as possible and the loss as close as possible to 0."
      ],
      "metadata": {
        "id": "KinvkSKWSJI1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4ha_zdkhpxZ"
      },
      "outputs": [],
      "source": [
        "histplot(history, \"First test model (50x50)\")    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> load the best model and check performance on unseen data"
      ],
      "metadata": {
        "id": "jE-HoevVTsQc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrqxpIs0lDKZ"
      },
      "outputs": [],
      "source": [
        "model.load_weights('best_model1.h5')\n",
        "\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "print(\"Accuracy score : %.1f\"%(accuracy_score(y_test, y_pred) * 100)) \n",
        "print()\n",
        "print(classification_report(y_test, y_pred))\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix : \")\n",
        "print(cf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> Misclassified samples only continue to this step if you have less than 10 misclassified samples</font>\n",
        "\n",
        "The most interesting samples to check are the misclassified samples. Which samples were misclassified?"
      ],
      "metadata": {
        "id": "WX52OwL5SQLE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Us-cJrkanKoX"
      },
      "outputs": [],
      "source": [
        "# find misclassified sample\n",
        "misclassified_samples = []\n",
        "for i in range(len(y_test)):\n",
        "  if y_test[i] != y_pred[i,0]:\n",
        "    misclassified_samples.append(i)\n",
        "print(misclassified_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> Change the samples back to strings"
      ],
      "metadata": {
        "id": "1o4xvZUhT7lM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = le.inverse_transform(y_pred)\n",
        "y_test = le.inverse_transform(y_test)\n",
        "y_test"
      ],
      "metadata": {
        "id": "Bb4nQcsd71MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> Visualise the misclassified samples"
      ],
      "metadata": {
        "id": "pnqNOVI-T823"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,len(misclassified_samples), figsize=(30,20))\n",
        "\n",
        "for indx, a in zip(misclassified_samples, axs):\n",
        "    a.imshow(X_test[indx])\n",
        "    a.set_axis_off()\n",
        "    a.title.set_text(y_pred[indx])"
      ],
      "metadata": {
        "id": "fY6FQHvCEKIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> Let's try to have a look at what is going wrong with the misclassified samples </font>"
      ],
      "metadata": {
        "id": "dExYb1BLT9_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,len(misclassified_samples), figsize=(30,20))\n",
        "\n",
        "for indx, a in zip(misclassified_samples, axs):\n",
        "    explainer = lime_image.LimeImageExplainer(verbose=False)\n",
        "    explanation = explainer.explain_instance(X_test[indx].astype('double'), model.predict, top_labels=5, hide_color=0, num_samples=500) # you can change num_samples from 100 to 2000, keep in mind, the higher the number, the more time needed for computations\n",
        "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=1000, hide_rest=True)\n",
        "    a.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
        "    a.set_axis_off()\n",
        "    a.title.set_text(y_pred[indx])"
      ],
      "metadata": {
        "id": "L8TEIRbV7txA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> Let's visualise it again, but this time we will see the entire image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8TjhA6iyT_9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,len(misclassified_samples), figsize=(30,20))\n",
        "\n",
        "for indx, a in zip(misclassified_samples, axs):\n",
        "    explainer = lime_image.LimeImageExplainer(verbose=False)\n",
        "    explanation = explainer.explain_instance(X_test[indx].astype('double'), model.predict, top_labels=5, hide_color=0, num_samples=500)\n",
        "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=1000, hide_rest=False)\n",
        "    a.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
        "    a.set_axis_off()\n",
        "    a.title.set_text(y_pred[indx])"
      ],
      "metadata": {
        "id": "owIkZh8VHWnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='deeppink'> Let's do the same, for some samples that were not misclassified. What is the AI model looking at?"
      ],
      "metadata": {
        "id": "K0DtXDmdUB0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "good_samples = []\n",
        "while len(good_samples) != len(misclassified_samples):\n",
        "  s = random.sample(range(1, len(y_test)), 1)\n",
        "  \n",
        "  if (s[0] not in misclassified_samples) & (s[0] not in good_samples):\n",
        "    good_samples.append(s[0])\n",
        "print(good_samples)"
      ],
      "metadata": {
        "id": "wHgJrAatCgT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,len(good_samples), figsize=(30,20))\n",
        "\n",
        "for indx, a in zip(good_samples, axs):\n",
        "    a.imshow(X_test[indx])\n",
        "    a.set_axis_off()\n",
        "    a.title.set_text(y_pred[indx])"
      ],
      "metadata": {
        "id": "mNGd1n5qESMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,len(good_samples), figsize=(30,20))\n",
        "\n",
        "for indx, a in zip(good_samples, axs):\n",
        "    explainer = lime_image.LimeImageExplainer(verbose=False)\n",
        "    explanation = explainer.explain_instance(X_test[indx].astype('double'), model.predict, top_labels=5, hide_color=0, num_samples=500)\n",
        "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=1000, hide_rest=True)\n",
        "    a.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
        "    a.set_axis_off()\n",
        "    a.title.set_text(y_pred[indx])"
      ],
      "metadata": {
        "id": "ICM9cXq9CXAb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}